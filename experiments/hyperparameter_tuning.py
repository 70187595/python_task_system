"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
"""

import sys
import os
import json
import numpy as np
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.models.neural_network import SimpleNeuralNetwork


def load_training_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
    try:
        with open('data/training_data/training_data.json', 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except FileNotFoundError:
        print("‚ùå –§–∞–π–ª —Å –æ–±—É—á–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None


def prepare_training_data(data):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    X = []
    y = []
    
    for item in data:
        features = item['features']
        target = item['target']
        
        feature_vector = [
            features['lines_of_code'] / 100.0,
            features['functions_count'] / 10.0,
            features['complexity'],
            features['nested_levels'] / 5.0,
            features['variable_names_length'] / 20.0,
            features['comments_ratio'],
            features['imports_count'] / 10.0,
            features['class_count'] / 5.0,
            features['error_handling'],
            features['test_coverage']
        ]
        
        X.append(feature_vector)
        y.append(target)
    
    return np.array(X), np.array(y)


def evaluate_model(network, X, y):
    """
    –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏
    
    Args:
        network: –û–±—É—á–µ–Ω–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å
        X: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        y: –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        
    Returns:
        dict: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    """
    predictions = []
    for i in range(len(X)):
        pred = network.predict(X[i:i+1])
        predictions.append(pred[0])
    
    predictions = np.array(predictions)
    
    # –°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (MAE)
    mae = np.mean(np.abs(y - predictions))
    
    # –°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ (MSE)
    mse = np.mean(np.square(y - predictions))
    
    # –ö–æ—Ä–µ–Ω—å –∏–∑ —Å—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –æ—à–∏–±–∫–∏ (RMSE)
    rmse = np.sqrt(mse)
    
    # MAE –¥–ª—è –∫–∞–∂–¥–æ–π –º–µ—Ç—Ä–∏–∫–∏
    mae_correctness = np.mean(np.abs(y[:, 0] - predictions[:, 0]))
    mae_efficiency = np.mean(np.abs(y[:, 1] - predictions[:, 1]))
    mae_readability = np.mean(np.abs(y[:, 2] - predictions[:, 2]))
    
    return {
        'mae': float(mae),
        'mse': float(mse),
        'rmse': float(rmse),
        'mae_correctness': float(mae_correctness),
        'mae_efficiency': float(mae_efficiency),
        'mae_readability': float(mae_readability)
    }


def run_experiment(config, X, y):
    """
    –ó–∞–ø—É—Å–∫ –æ–¥–Ω–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    
    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
        X: –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        y: –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        
    Returns:
        dict: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    """
    print(f"\n{'='*70}")
    print(f"üß™ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç: {config['name']}")
    print(f"{'='*70}")
    print(f"   Hidden size: {config['hidden_size']}")
    print(f"   Learning rate: {config['learning_rate']}")
    print(f"   Epochs: {config['epochs']}")
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç—å —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    network = SimpleNeuralNetwork(
        input_size=X.shape[1],
        hidden_size=config['hidden_size'],
        output_size=y.shape[1]
    )
    network.learning_rate = config['learning_rate']
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    training_data = [(X[i:i+1], y[i:i+1]) for i in range(len(X))]
    
    # –û–±—É—á–∞–µ–º
    start_time = datetime.now()
    history = network.train(training_data, epochs=config['epochs'])
    training_time = (datetime.now() - start_time).total_seconds()
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º
    metrics = evaluate_model(network, X, y)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {
        'config': config,
        'history': history,
        'metrics': metrics,
        'training_time': training_time,
        'final_loss': history['loss'][-1]
    }
    
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"   MAE: {metrics['mae']:.4f}")
    print(f"   RMSE: {metrics['rmse']:.4f}")
    print(f"   Final Loss: {results['final_loss']:.4f}")
    print(f"   Training Time: {training_time:.2f}s")
    
    return results


def hyperparameter_tuning():
    """–ü–æ–¥–±–æ—Ä –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    print("üî¨ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´ –° –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–ê–ú–ò")
    print("=" * 70)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    data = load_training_data()
    if data is None:
        return
    
    X, y = prepare_training_data(data)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –ø—Ä–∏–º–µ—Ä–æ–≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
    experiments = [
        {
            'name': 'Baseline (lr=0.01, hidden=8)',
            'hidden_size': 8,
            'learning_rate': 0.01,
            'epochs': 2000
        },
        {
            'name': '–£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π (hidden=12)',
            'hidden_size': 12,
            'learning_rate': 0.01,
            'epochs': 2000
        },
        {
            'name': '–£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π (hidden=5)',
            'hidden_size': 5,
            'learning_rate': 0.01,
            'epochs': 2000
        },
        {
            'name': '–ü–æ–≤—ã—à–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (lr=0.05)',
            'hidden_size': 8,
            'learning_rate': 0.05,
            'epochs': 2000
        },
        {
            'name': '–ü–æ–Ω–∏–∂–µ–Ω–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (lr=0.005)',
            'hidden_size': 8,
            'learning_rate': 0.005,
            'epochs': 2000
        }
    ]
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
    all_results = []
    for config in experiments:
        results = run_experiment(config, X, y)
        all_results.append(results)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    os.makedirs('experiments/results', exist_ok=True)
    output_file = f'experiments/results/hyperparameter_tuning_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*70}")
    print(f"‚úÖ –í—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!")
    print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print(f"\n{'='*70}")
    print("üìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print(f"{'='*70}")
    print(f"{'–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç':<50} {'MAE':>8} {'RMSE':>8} {'Loss':>8}")
    print("-" * 70)
    
    for result in all_results:
        name = result['config']['name']
        mae = result['metrics']['mae']
        rmse = result['metrics']['rmse']
        loss = result['final_loss']
        print(f"{name:<50} {mae:>8.4f} {rmse:>8.4f} {loss:>8.4f}")
    
    # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    best_result = min(all_results, key=lambda x: x['metrics']['mae'])
    print(f"\nüèÜ –õ–£–ß–®–ò–ô –†–ï–ó–£–õ–¨–¢–ê–¢: {best_result['config']['name']}")
    print(f"   MAE: {best_result['metrics']['mae']:.4f}")
    print(f"   Hidden size: {best_result['config']['hidden_size']}")
    print(f"   Learning rate: {best_result['config']['learning_rate']}")


if __name__ == '__main__':
    hyperparameter_tuning()

