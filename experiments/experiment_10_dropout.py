"""
–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 10: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å dropout 0.3
–¶–µ–ª—å: –£–º–µ–Ω—å—à–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ —É–ª—É—á—à–∏—Ç—å –æ–±–æ–±—â–∞—é—â—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
"""

import sys
import os
import json
import numpy as np

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.models.neural_network import SimpleNeuralNetwork


def load_and_prepare_data():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
    with open('data/training_data/training_data.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    X = []
    y = []
    
    for item in data:
        features = item['features']
        target = item['target']
        
        feature_vector = [
            features['lines_of_code'] / 100.0,
            features['functions_count'] / 10.0,
            features['complexity'],
            features['nested_levels'] / 5.0,
            features['variable_names_length'] / 20.0,
            features['comments_ratio'],
            features['imports_count'] / 10.0,
            features['class_count'] / 5.0,
            features['error_handling'],
            features['test_coverage']
        ]
        
        X.append(feature_vector)
        y.append(target)
    
    return np.array(X), np.array(y), len(data)


def main():
    print("üß™ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢ 10: Dropout 0.3")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    X, y, data_size = load_and_prepare_data()
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {data_size} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ—Ç—å —Å dropout
    network = SimpleNeuralNetwork(
        input_size=10,
        hidden_size=8,
        output_size=3,
        activation='sigmoid',
        dropout_rate=0.3  # 30% –Ω–µ–π—Ä–æ–Ω–æ–≤ –±—É–¥—É—Ç "–≤—ã–∫–ª—é—á–µ–Ω—ã" –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
    )
    
    # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞
    network.weights_input_hidden = np.random.randn(10, 8) * 0.1
    network.weights_hidden_output = np.random.randn(8, 3) * 0.1
    network.bias_hidden = np.zeros((1, 8))
    network.bias_output = np.zeros((1, 3))
    network.learning_rate = 0.01
    
    print(f"\nüîß –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:")
    print(f"   Input: 10, Hidden: 8, Output: 3")
    print(f"   Learning rate: 0.01")
    print(f"   Epochs: 2000")
    print(f"   Activation: Sigmoid")
    print(f"   Dropout rate: 0.3 (30% –Ω–µ–π—Ä–æ–Ω–æ–≤ –æ—Ç–∫–ª—é—á–∞—é—Ç—Å—è)")
    
    print(f"\nüìö –ß—Ç–æ —Ç–∞–∫–æ–µ Dropout:")
    print(f"   Dropout - —ç—Ç–æ —Ç–µ—Ö–Ω–∏–∫–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º")
    print(f"   '–≤—ã–∫–ª—é—á–∞–µ—Ç' –Ω–µ–π—Ä–æ–Ω—ã –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è. –≠—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç:")
    print(f"   ‚Ä¢ –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ")
    print(f"   ‚Ä¢ –£–ª—É—á—à–∏—Ç—å –æ–±–æ–±—â–∞—é—â—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å")
    print(f"   ‚Ä¢ –ó–∞—Å—Ç–∞–≤–∏—Ç—å —Å–µ—Ç—å —É—á–∏—Ç—å—Å—è –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º")
    
    # –û–±—É—á–∞–µ–º
    training_data = [(X[i:i+1], y[i:i+1]) for i in range(len(X))]
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    
    history = network.train(training_data, epochs=2000)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    os.makedirs('experiments/results', exist_ok=True)
    network.save_model('experiments/results/model_exp10_dropout.json')
    
    with open('experiments/results/history_exp10_dropout.json', 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"   –ù–∞—á–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {history['loss'][0]:.4f}")
    print(f"   –ö–æ–Ω–µ—á–Ω–∞—è –æ—à–∏–±–∫–∞: {history['loss'][-1]:.4f}")
    improvement = (1 - history['loss'][-1]/history['loss'][0])*100 if history['loss'][0] > 0 else 0
    print(f"   –£–ª—É—á—à–µ–Ω–∏–µ: {improvement:.1f}%")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö (–ë–ï–ó dropout)
    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö (–±–µ–∑ dropout):")
    test_indices = [0, 50, 100, 150, 200]
    total_error = 0
    test_count = 0
    
    for idx in test_indices:
        if idx < len(X):
            # –í–∞–∂–Ω–æ: training=False, —á—Ç–æ–±—ã dropout –Ω–µ –ø—Ä–∏–º–µ–Ω—è–ª—Å—è –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            prediction = network.predict(X[idx]).flatten()
            target = y[idx]
            error = np.mean(np.abs(prediction - target))
            total_error += error
            test_count += 1
            
            print(f"\n   –ü—Ä–∏–º–µ—Ä {idx}:")
            print(f"   –û–∂–∏–¥–∞–µ–º–æ–µ:    [{target[0]:.2f}, {target[1]:.2f}, {target[2]:.2f}]")
            print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: [{prediction[0]:.2f}, {prediction[1]:.2f}, {prediction[2]:.2f}]")
            print(f"   –û—à–∏–±–∫–∞: {error:.4f}")
    
    avg_test_error = total_error / test_count if test_count > 0 else 0
    print(f"\n   üìä –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–∞—Ö: {avg_test_error:.4f}")
    
    print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: experiments/results/model_exp10_dropout.json")
    print(f"‚úÖ –ò—Å—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: experiments/results/history_exp10_dropout.json")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏
    print(f"\nüìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏:")
    print(f"   Baseline (–±–µ–∑ dropout):            0.0056")
    print(f"   –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 5 (lr=0.05):           0.0038 üèÜ")
    print(f"   –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 8 (ReLU):              0.0047")
    print(f"   –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 9 (2 —Å–ª–æ—è):            0.0047")
    print(f"   –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 10 (dropout 0.3):      {history['loss'][-1]:.4f}")
    
    baseline_error = 0.0056
    if history['loss'][-1] < baseline_error:
        improvement_vs_baseline = ((baseline_error - history['loss'][-1])/baseline_error)*100
        print(f"   ‚úÖ Dropout –ª—É—á—à–µ baseline –Ω–∞ {improvement_vs_baseline:.1f}%")
    elif history['loss'][-1] > baseline_error:
        degradation = ((history['loss'][-1] - baseline_error)/baseline_error)*100
        print(f"   ‚ö†Ô∏è  Dropout —Ö—É–∂–µ baseline –Ω–∞ {degradation:.1f}%")
    else:
        print(f"   üîÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã —Å baseline")
    
    print(f"\nüí° –í—ã–≤–æ–¥—ã:")
    if history['loss'][-1] < 0.0045:
        print(f"   ‚úÖ Dropout –ø–æ–∫–∞–∑–∞–ª –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã!")
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å—Ç–∞–ª–∞ –±–æ–ª–µ–µ —É—Å—Ç–æ–π—á–∏–≤–æ–π –∫ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é")
    elif history['loss'][-1] < 0.0056:
        print(f"   ‚úÖ Dropout –ø–æ–º–æ–≥ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ")
        print(f"   üí° –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ª—É—á—à–µ –æ–±–æ–±—â–∞—Ç—å—Å—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    else:
        print(f"   ‚ö†Ô∏è  Dropout –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º –¥–ª—è —ç—Ç–æ–π –∑–∞–¥–∞—á–∏")
        print(f"   üí° –í–æ–∑–º–æ–∂–Ω–æ, —Å—Ç–æ–∏—Ç –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –º–µ–Ω—å—à–∏–π dropout_rate (0.1-0.2)")
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    print(f"\nüìñ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
    print(f"   ‚Ä¢ –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: 30% –Ω–µ–π—Ä–æ–Ω–æ–≤ —Å–ª—É—á–∞–π–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω—ã")
    print(f"   ‚Ä¢ –í–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –≤—Å–µ –Ω–µ–π—Ä–æ–Ω—ã –∞–∫—Ç–∏–≤–Ω—ã")
    print(f"   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 'inverted dropout' –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è")


if __name__ == '__main__':
    main()

