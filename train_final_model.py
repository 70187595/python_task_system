"""
–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

–ù–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –≤—ã–±—Ä–∞–Ω–∞ –ª—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:
- Learning rate: 0.05 (–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 5 - –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç 0.0038)
- Activation: ReLU (–±—ã—Å—Ç—Ä–µ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ sigmoid)
- Hidden size: 8 –Ω–µ–π—Ä–æ–Ω–æ–≤ (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å)
- Epochs: 2000 (–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏)
"""

import json
import numpy as np
from app.models.neural_network import SimpleNeuralNetwork

def load_training_data():
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    
    –ß–∏—Ç–∞–µ—Ç JSON-—Ñ–∞–π–ª —Å –æ–±—É—á–∞—é—â–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Ö
    –≤ numpy –º–∞—Å—Å–∏–≤—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ü—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
    –∫ –∫–∞–∂–¥–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É —Å–æ–≥–ª–∞—Å–Ω–æ –µ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É –∑–Ω–∞—á–µ–Ω–∏–π.
    
    Returns:
        tuple: (X, y) –≥–¥–µ X - –º–∞—Å—Å–∏–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (N√ó10), y - –º–∞—Å—Å–∏–≤ —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (N√ó3)
    """
    with open('data/training_data/training_data.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    X = []
    y = []
    
    for item in data:
        features = item['features']
        target = item['target']
        
        feature_vector = [
            features['lines_of_code'] / 100.0,
            features['functions_count'] / 10.0,
            features['complexity'],
            features['nested_levels'] / 5.0,
            features['variable_names_length'] / 20.0,
            features['comments_ratio'],
            features['imports_count'] / 10.0,
            features['class_count'] / 5.0,
            features['error_handling'],
            features['test_coverage']
        ]
        
        X.append(feature_vector)
        y.append(target)
    
    return np.array(X), np.array(y)


def main():
    """
    –û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    
    –°–æ–∑–¥–∞–µ—Ç –∏ –æ–±—É—á–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏,
    –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ 10 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤:
    - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: 10 –≤—Ö–æ–¥–æ–≤ ‚Üí 8 —Å–∫—Ä—ã—Ç—ã—Ö ‚Üí 3 –≤—ã—Ö–æ–¥–∞
    - Learning rate: 0.05 (–ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ 5)
    - –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: ReLU (–±—ã—Å—Ç—Ä–µ–µ –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ sigmoid)
    - –≠–ø–æ—Ö–∏: 2000 (–æ–ø—Ç–∏–º–∞–ª—å–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å)
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª:
    1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    2. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    3. –û–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è (–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–æ–≤—ã—Ö –≤–µ—Å–æ–≤)
    4. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö
    5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
    
    –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤:
    - data/models/model_final.json
    - data/models/neural_network.json (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è)
    - data/models/training_history_final.json
    """
    print("=" * 70)
    print("üéì –û–ë–£–ß–ï–ù–ò–ï –§–ò–ù–ê–õ–¨–ù–û–ô –ú–û–î–ï–õ–ò")
    print("=" * 70)
    
    print("\nüìã –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (–Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤):")
    print("   ‚Ä¢ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: 10 ‚Üí 8 ‚Üí 3")
    print("   ‚Ä¢ Learning rate: 0.05 (üèÜ –õ—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–µ 5)")
    print("   ‚Ä¢ Activation: ReLU (–ë—ã—Å—Ç—Ä–µ–µ sigmoid)")
    print("   ‚Ä¢ Epochs: 2000")
    print("   ‚Ä¢ Dropout: 0.0 (–ù–µ –Ω—É–∂–µ–Ω –¥–ª—è –º–∞–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞)")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    X, y = load_training_data()
    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(X)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å –Ω—É–ª—è (–Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é)
    print("\nüß† –°–æ–∑–¥–∞–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏...")
    network = SimpleNeuralNetwork(
        input_size=10,
        hidden_size=8,
        output_size=3,
        activation='relu'
    )
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    network.learning_rate = 0.05
    
    # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å–∞ (–æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è)
    network.weights_input_hidden = np.random.randn(10, 8) * 0.1
    network.weights_hidden_output = np.random.randn(8, 3) * 0.1
    network.bias_hidden = np.zeros((1, 8))
    network.bias_output = np.zeros((1, 3))
    
    print("   ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
    
    # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    total_params = (10 * 8) + 8 + (8 * 3) + 3
    print(f"\nüìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
    print(f"   ‚Ä¢ W1 (10√ó8): 80 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    print(f"   ‚Ä¢ b1: 8 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    print(f"   ‚Ä¢ W2 (8√ó3): 24 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
    print(f"   ‚Ä¢ b2: 3 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
    print(f"   ‚Ä¢ –í—Å–µ–≥–æ: {total_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    training_data = [(X[i:i+1], y[i:i+1]) for i in range(len(X))]
    
    print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...")
    print("   (–ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 100 —ç–ø–æ—Ö)")
    print()
    
    # –û–±—É—á–µ–Ω–∏–µ
    history = network.train(training_data, epochs=2000)
    
    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print("\n" + "=" * 70)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 70)
    print(f"\n   –ù–∞—á–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞:  {history['loss'][0]:.6f}")
    print(f"   –ö–æ–Ω–µ—á–Ω–∞—è –æ—à–∏–±–∫–∞:   {history['loss'][-1]:.6f}")
    
    improvement = (1 - history['loss'][-1]/history['loss'][0])*100 if history['loss'][0] > 0 else 0
    print(f"   –£–ª—É—á—à–µ–Ω–∏–µ:         {improvement:.1f}%")
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏
    print("\nüìà –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–º–∏:")
    print(f"   Baseline (lr=0.01):           0.0056")
    print(f"   –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 5 (lr=0.05):      0.0038 üèÜ")
    print(f"   –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å:             {history['loss'][-1]:.4f}")
    
    if history['loss'][-1] <= 0.0040:
        print(f"\n   ‚úÖ –û–¢–õ–ò–ß–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ production")
    elif history['loss'][-1] <= 0.0050:
        print(f"\n   ‚úÖ –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ")
    else:
        print(f"\n   ‚ö†Ô∏è  –†–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–∏–µ–º–ª–µ–º—ã–π, –Ω–æ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∏–º–µ—Ä–∞—Ö
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö:")
    test_indices = [0, 50, 100, 150, 200]
    total_error = 0
    test_count = 0
    
    for idx in test_indices:
        if idx < len(X):
            prediction = network.predict(X[idx]).flatten()
            target = y[idx]
            error = np.mean(np.abs(prediction - target))
            total_error += error
            test_count += 1
            
            print(f"\n   –ü—Ä–∏–º–µ—Ä {idx}:")
            print(f"   –û–∂–∏–¥–∞–µ–º–æ–µ:    [{target[0]:.2f}, {target[1]:.2f}, {target[2]:.2f}]")
            print(f"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: [{prediction[0]:.2f}, {prediction[1]:.2f}, {prediction[2]:.2f}]")
            print(f"   –û—à–∏–±–∫–∞:       {error:.4f} ", end="")
            if error < 0.05:
                print("‚úÖ")
            elif error < 0.10:
                print("‚ö†Ô∏è")
            else:
                print("‚ùå")
    
    avg_test_error = total_error / test_count if test_count > 0 else 0
    print(f"\n   üìä –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–∞—Ö: {avg_test_error:.4f}")
    
    # –û—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏
    accuracy = (1 - avg_test_error) * 100
    print(f"   üìä –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏:         ~{accuracy:.1f}%")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏...")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    network.save_model('data/models/model_final.json')
    print("   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data/models/model_final.json")
    
    # –ó–∞–º–µ–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å
    network.save_model('data/models/neural_network.json')
    print("   ‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω–æ: data/models/neural_network.json")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
    with open('data/models/training_history_final.json', 'w', encoding='utf-8') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)
    print("   ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: data/models/training_history_final.json")
    
    print("\n" + "=" * 70)
    print("üéâ –§–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨ –£–°–ü–ï–®–ù–û –û–ë–£–ß–ï–ù–ê!")
    print("=" * 70)
    print("\nüì¶ –ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é:")
    print("   ‚Ä¢ –ú–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º 10 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")
    print("   ‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª—É—á—à–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (lr=0.05, ReLU)")
    print(f"   ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å: ~{accuracy:.1f}%")
    print(f"   ‚Ä¢ –û—à–∏–±–∫–∞: {history['loss'][-1]:.4f}")
    print("\n‚ú® –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ production!")


if __name__ == '__main__':
    main()

